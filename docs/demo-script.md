

Alright, letâ€™s script your Christmas Eve showtime ğŸ˜Š

Hereâ€™s a \*\*concise â€œTour of EVA Heroesâ€\*\* you can literally read or adapt while you click through the demo.



You can aim for ~10â€“15 minutes end-to-end.



---



\## 0. Opening â€“ Set the stage (Home page)



\*\*Where you are:\*\* EVA Suite home, product grid.



\*\*Script:\*\*



> â€œWelcome to my personal EVA Suite lab.

> This is not a production system â€“ itâ€™s a sandbox where Iâ€™m exploring what an integrated EVA ecosystem could look like.

>

> On this page you see 24 EVA products grouped by theme: operations, decision-support, developer tools, accessibility, impact, and moonshots.

>

> For todayâ€™s demo, Iâ€™ll walk you through six â€˜heroâ€™ experiences â€“ about one quarter of the Suite â€“ just enough to show the shape of what EVA could become without pretending everything is finished.â€



(Scroll a bit through the product cards.)



> â€œEach card represents a product idea. Some are just conceptual, others have a working demo behind them. Iâ€™ll start with the operational nerve centre: \*\*EVA LiveOps\*\*.â€



Click \*\*EVA LiveOps\*\*.



---



\## 1. Hero #1 â€“ EVA LiveOps (Ops \& metrics)



\*\*Script:\*\*



> â€œEVA LiveOps is the operational cockpit.

> Think of it as â€˜how is EVA doing right now?â€™ â€“ usage, errors, latency, and cost, all in one place.â€



Point to the KPIs.



> â€œAt the top we have the classic four: total sessions, error rate, p95 latency, and APIM cost for the last 24 hours.

> The data you see here is mock, but the structure is exactly what weâ€™d wire to real APIM and logging.â€



Point to the bar chart.



> â€œOn the left, a simple sessions-by-time-of-day chart gives a quick sense of peak usage. Again, just a small example â€“ the goal is to show that EVA can surface metrics in an opinionated way, not just a sea of logs.â€



Point to the â€œEVA LiveOps Copilotâ€ panel.



> â€œOn the right is the EVA LiveOps Copilot idea. Instead of a human staring at charts, EVA gives you AI-style summaries from different viewpoints: overview, reliability, performance, and cost.

>

> As I switch views, the narrative changes: it highlights the key findings and suggests concrete next steps. In production, this would be driven by real telemetry plus guardrails; here itâ€™s a static demo to show the concept.â€



Click through a couple of viewpoints.



> â€œSo LiveOps is about \*\*seeing and understanding EVA in production\*\*, quickly, with AI helping you focus on what matters.â€



Then:



> â€œNow let me jump from operations to \*\*decision-support\*\*: EVA DA.â€



Go back, click \*\*EVA DA\*\* product.



---



\## 2. Hero #2 â€“ EVA DA (Decision-support demo)



\*\*Script:\*\*



> â€œEVA DA is the decision-support side.

> The idea is: you describe a case, and EVA combines curated guidance, jurisprudence, and machine-readable rules to help an officer reason about eligibility.â€



Show the domain selector.



> â€œThis demo focuses on two domains: CPP-D Disability and EI. Itâ€™s all mock data â€“ no real policies or real clients â€“ but it shows the pattern.â€



Select CPP-D and show the prefilled question.



> â€œHere I have a CPP-D scenario with a severe and prolonged condition, stopped working 18 months ago, contributions are fine. I click \*Ask EVA DA\*â€¦â€



Click the button.



> â€œâ€¦and the demo returns a structured answer: a decision, an explanation, the key conditions that were evaluated, and the sources it would have used.â€



Point to each area.



> â€œIn a real implementation, RAG would provide the references and a rules engine would do the actual logical evaluation. The LLM is then used to explain, not to improvise the decision.

>

> The banner at the bottom reminds us: this is static, \*\*demo-only\*\*, and must not be used on real client files. But it shows what neurosymbolic EVA â€“ RAG plus rules â€“ could look like in practice.â€



Optional: flip to the EI domain quickly to show a second scenario.



> â€œSo LiveOps is â€˜how EVA is behavingâ€™, and EVA DA is â€˜how EVA can help humans make better, explainable decisionsâ€™.

>

> Next, Iâ€™ll show you how EVA could help \*\*build\*\* all this: the DevTools and AI Agile Crew.â€



Back, click \*\*EVA DevTools / AI Agile Crew\*\* product.



---



\## 3. Hero #3 â€“ EVA DevTools / AI Agile Crew (Dev workflow)



\*\*Script:\*\*



> â€œThis product is about \*\*how we develop EVA itself\*\*.

> The idea is: instead of just human teams, you have an AI Dev Crew â€“ a group of specialized agents â€“ working alongside us in sprints.â€



Point to sprint info and selector.



> â€œThis view is focused on Sprint 3, with the goal of delivering the three hero demos we just saw: LiveOps, EVA DA, and Dev Crew itself.â€



Show the Agents panel.



> â€œOn the left we have the agents: Planner, Frontend, Docs, QA â€“ each with a role, current status, and capacity. Itâ€™s a very simple representation of â€˜who is doing whatâ€™ in an AI-supported dev team.â€



Show the Tasks panel.



> â€œIn the tasks panel, we see what theyâ€™re working on: building the EVA Suite shell, LiveOps dashboard, EVA DA demo, Dev Crew dashboard, documentation, QA. Again, all mock, but structured in a way that a Dev Orchestrator could actually consume.â€



Point to the AI Sprint Coach panel.



> â€œOn the right is the AI Sprint Coach. It provides a synthesized view: are we on track, what are the highlights, what are the risks, what should we do next?

>

> Behind this hero is a bigger idea: using plans stored in GitHub and an AI Dev Orchestrator to actually generate code, docs, and tests â€“ with humans reviewing and steering.â€



> â€œSo this hero isnâ€™t about citizens or call centres; itâ€™s about \*\*our own productivity\*\* as a department building AI safely and quickly.â€



> â€œNow Iâ€™ll switch gears and show how EVA can support \*\*accessibility and bilingual web work\*\*.â€



Back, click \*\*EVA Accessibility\*\* product.



---



\## 4. Hero #4 â€“ EVA Accessibility (A11y + Dev coaching)



\*\*Script:\*\*



> â€œEVA Accessibility is aimed at front-end developers and designers. Itâ€™s a companion to WCAG and internal accessibility standards.â€



Point to scan target and summary.



> â€œHere we pretend we ran an accessibility scan on the EVA Suite product explorer. The target, timestamp, and summary show up here: overall grade, counts of issues and passes. All of this is static for now, but it follows the pattern of a real report.â€



Scroll the issues list.



> â€œBelow we see a curated set of findings: contrast, skip links, headings, structure. For each issue we show a WCAG reference, severity, area, and a suggested fix â€“ written in plain language so a developer can act on it.â€



Point to the AI Accessibility Coach panel.



> â€œOn the right, the AI Accessibility Coach distills the quick wins: â€˜add a skip linkâ€™, â€˜fix contrastâ€™, â€˜use semantic headingsâ€™, and so on, plus a clear disclaimer that this is a demo, not a real audit.

>

> The long-term vision is that EVA could sit inside the developer workflow, continuously analysing pages and suggesting accessible, bilingual patterns.â€



> â€œFrom accessibility, letâ€™s jump to something executives care about a lot: \*\*impact and ROI\*\*.â€



Back, click \*\*EVA Impact Analyzer\*\* product.



---



\## 5. Hero #5 â€“ EVA Impact Analyzer (ROI \& payback)



\*\*Script:\*\*



> â€œEVA Impact Analyzer is a simple way to reason about the order of magnitude of EVAâ€™s impact â€“ hours saved, cost avoided, and payback.â€



Show the baseline and scenario selector.



> â€œAt the top we have a baseline description â€“ for example, a department-wide rollout for knowledge workers â€“ and a set of illustrative scenarios: Conservative, Expected, and Ambitious. These numbers are synthetic; they are here to show the logic, not to forecast.â€



Select one scenario (e.g., Expected).



> â€œOn the left, we see the inputs: number of employees, hours saved per week, hourly cost, and platform cost per year. On the right we see the computed outputs: annual hours saved, gross and net savings, ROI percentage, and payback in months.â€



Point to Impact Narrator.



> â€œThe Impact Narrator panel then explains the story in human terms: what this scenario would mean in practice and why it matters.

>

> This is exactly the kind of thing executives and CFOs ask: â€˜If I give you X, what do I get back, and how fast?â€™ This tool doesnâ€™t replace detailed business cases, but it gives a fast, transparent starting point.â€



> â€œFinally, I want to show a more systemic view: \*\*how EVA plugs into real service journeys\*\*.â€



Back, click \*\*EVA Process Mapper\*\* product.



---



\## 6. Hero #6 â€“ EVA Process Mapper (Journey \& system view)



\*\*Script:\*\*



> â€œEVA Process Mapper is about \*\*seeing the whole journey\*\* â€“ citizen, agents, systems, and EVA in between.â€



Point to header and scenario.



> â€œIn this demo weâ€™re looking at a simplified OAS enquiry flow. This is not an official process map â€“ itâ€™s a fictional example to illustrate how EVA might fit into a citizen-to-system journey.â€



Scroll the swimlane layout.



> â€œEach lane is an actor: the citizen, IVR, call centre agent, EVA Suite, and program systems. Within each lane, the steps are ordered â€“ dialing the number, going through the IVR, talking to the agent, EVA fetching policy and applying simplified rules, and finally explaining next steps to the citizen.â€



Highlight the â€œEVA-assistedâ€ tags.



> â€œThe tags show where EVA is directly involved â€“ for example, retrieving curated OAS content and applying basic eligibility rules. Everything is static here, but the visual tells a story: EVA doesnâ€™t replace humans or systems; it \*\*sits in the flow\*\*, making each step smarter and more explainable.â€



Show the Process Coach panel.



> â€œThe EVA Process Coach summarizes what this map is showing and where the opportunities are: better capture of client context, improved routing, deeper integration with downstream systems, and a disclaimer that this is a demo, not an authoritative view.â€



---



\## 7. Closing â€“ Tie it all together



Go back to the home/product grid.



\*\*Script:\*\*



> â€œSo that was a quick tour of six EVA Suite heroes:

>

> \* LiveOps for operational visibility,

> \* EVA DA for explainable decision-support,

> \* DevTools and the AI Dev Crew for building all this faster and safely,

> \* EVA Accessibility for inclusive, bilingual front-ends,

> \* EVA Impact Analyzer for ROI and payback, and

> \* EVA Process Mapper for journey-level thinking.

>

> The other 18 products you see here are at different levels of maturity â€“ some are just ideas, some are placeholders for future work.

>

> The point of this lab isnâ€™t that everything is finished. The point is that the \*\*shape\*\* of the ecosystem is clear: a coherent EVA Suite where operations, decisions, development, accessibility, impact, and process all connect.

>

> And the fun part is that a lot of this is being built with AI assistance itself â€“ GitHub Copilot, ChatGPT, and, eventually, EVAâ€™s own AI Dev Orchestrator.

>

> This is my sandbox for exploring what a Canadian, public-sector-grade EVA platform could become.â€



If you want, you can end with a personal line:



> â€œFor now, itâ€™s just me, a laptop, Copilot, and this EVA Suite lab. But this gives a taste of what we could build together as a department.â€



---



If youâ€™d like, I can also help you write a \*\*1-page text\*\* that matches this tour, to share with colleagues who wonâ€™t see the live demo.



