
\label{sec:theory}
\begin{figure}[tb]
    \centering
    \includegraphics[width=0.85\linewidth]{Figs/four_aware.pdf} 
    \caption{Four dimensions of ``main'' awareness. Metacognition monitors the subject's own processes and gives rise to self-awareness, social awareness of other individuals and the social collective, and situational awareness of the non-agent environment}
    \label{fig:four_aware}
\end{figure}

\section{Theoretical Foundations of AI Awareness}

This section reviews key definitions, frameworks, and theoretical approaches to awareness in human and artificial intelligence research. We clarify conceptual ambiguities that arise from conflating distinct research domains and outline the specific targets of awareness-related inquiry. According to the \textit{Psychology Encyclopedia}, awareness denotes the perception or knowledge of an object or event \citep{apa_awareness}. When an agent possesses ``knowledge and a knowing state'' about an internal or external situation or fact, it is said to exhibit awareness of the target in question. Foundational studies have demarcated a persistent divide between consciousness (\ie, being in a state) and awareness (\ie, functionalistic consciousness) \citep{yates1985content, turing1950mind, duval1972objective, nagel1974bat, crick1990towards, block1995confusion, toglia2000understanding}. Consciousness refers to the experience of being in a particular mental state\textemdash having a \emph{subjective} point of view \citep{nagel1974bat}. However, awareness and \textit{phenomenological consciousness} are frequently used interchangeably or conflated in the literature, raising ongoing debates about whether they should be analytically disentangled \citep{block1995confusion, newen2003self, Morin2006selfawareness}. When an agent possesses consciousness, the ability to become aware of the states of a target, especially (but not only) mental states (\eg, perceptions, emotions, and attitudes), as one’s own states.

Empirical findings from blind spot studies\footnote{Blind spot study refers to the optic disc in the human retina, where the optic nerve exits the eye that lacks photoreceptors and hence cannot detect light.} and learning mechanism studies suggest that one can be aware of information without being explicitly conscious of it \citep{apa_awareness} in the domains of visual processing \citep{derrien2022nature} or implicit learning \citep{crick1990towards}. Extending this distinction to AI, \citet{Dehaene2017} distinguish between a mere global workplace with information availability (see \citep{baars1993cognitive} and \citep{baars2002conscious}), consciousness with self-monitoring, and reflective consciousness, indicating that knowledge gathering and processing can operate at different levels with subjective experience. To prove there is an \emph{extra} layer of reflective experience, where the AI assesses its own knowledge and decisions, is difficult, if not impossible. Having a conceptual or computational self-model is not the same as having the subjective, qualitative self-awareness that humans have, while neurobiological research dodged answering the origin of the later \citep{lou2017towards}. Since phenomenal observations do not provide sufficient evidence for the existence of consciousness, the \textit{``hard problem''}\footnote{\citet{chalmers1995facing,chalmers2023could} argue that explaining information processing, \eg, the brain receiving the red light of an apple, is an easy question of consciousness, whereas the existence of subjective experience, \eg, the private experience of ``redness'' in one's mind, constitutes the hard problem.} of AI consciousness remains scientifically unresolved \citep{nagel1974bat, chalmers2023could}. As such, before reaching a convincing testing method for ontological consciousness, we encourage shifting from metaphysical analysis to the establishment of a measurable awareness framework. 

We define awareness as the cognitive knowledge, followed by a comprehensive fourfold structure based on the types of targets of awareness, \ie, the objects of cognition. We reconciled the discrepancies of conceptualization across various studies, analyzed evaluation criteria among AIs for each type of awareness, and discussed AIs' achievement and potential in developing humanlike agents with holistic awareness of everything. The four core categories are \textbf{metacognition}, \textbf{self-awareness}, \textbf{social awareness}, and \textbf{situational awareness}, and the clue to this classification could be traced back to early attempts at analyzing the components of consciousness. \citet{tulving1985memory} identifies anoetic, noetic, and autonoetic forms of consciousness. Anoetic content reflects a fundamental first-person experience without explicit knowledge that is bound to situations. The other two advanced forms present a knowledge-aware conscious stage in noetic content and an introspective stage in autonoetic consciousness \citep{tulving1985memory, vandekerckhove2014emergence}. The triadic framework elucidates the distinction between basic situational awareness, knowledge awareness, and self-awareness. \citet{tulving1985memory} does not further subdivide ``knowledge awareness'' while our taxonomy highlights distinctions between internal and external sources of information and their functional implications, \ie, distinctions between self-knowledge, meta-level awareness, and situational awareness. We particularly underscore the critical role of metacognitive knowledge for AI agents, a categorization broadly validated within relevant literature. \citet{Morin2006selfawareness}'s integrative framework reaches similar results, spanning concepts of ``reflective/extended'' consciousness (higher self-reflection) and recursive self-awareness (\ie, awareness of being self-aware), buttressing the latter developed metacognitive knowledge. Although the entry points of the two frameworks differ, distinctions such as situational awareness and reflective self-awareness are consistently recognized. 

\mytcolorbox{Focusing on \emph{awareness}, rather than \emph{consciousness}, enables measurable, actionable progress in both cognitive science and AI, bridging conceptual divides and grounding research in functional, testable criteria.}

 
\begin{figure}[tb]
    \centering
    \begin{subfigure}[t]{0.53\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figs/meta-cognition.png}
        \caption{Metacognition}
        \label{fig:meta-cognition}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.37\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figs/self-awareness.png}
        \caption{Self-awareness}
        \label{fig:self-awareness}
    \end{subfigure}
    \caption{Illustration of metacognition and self-awareness as related but distinct components in awareness models}
    \label{fig:first-two}
\end{figure}

\subsection{Major Types of Awareness} 

\paragraph{Metacognition}

\textit{Metacognition}, originally proposed as ``thinking about thinking,'' refers to the capacity to actively perceive, monitor, and regulate one's own cognitive processes \citep{flavell1979metacognition, nelson1990metamemory, Rosenthal1986-ROSTCO, nelson1996consciousness, kornell2009metacognition}. \citet{nelson1990metamemory} distinguishes between metacognitive knowledge and metacognitive regulation, proposing a structural framework in which an object-level cognitive system provides input to a meta-level ``central executive.'' This central executive component monitors cognitive states through mechanisms such as confidence judgments (\ie, the association between task accuracy and confidence level \citep{fleming2014measure}) and exerts control via strategic decisions and study-time allocation. Metacognitive knowledge encompasses a wide range of components: meta-level knowledge and beliefs pertain to an individual’s cognitive abilities, current tasks, past experiences, and specific process features (\eg, metamemory); metacognitive regulation involves active deployment of cognitive processes or resources, planning, monitoring, and strategic adjustments \citep{efklides2001metacognitive, dunlosky2008metacognition, dunlosky2013handbook, proust2013philosophy, fleur2021metacognition, COX2005104, steyvers2025metacognition, crystal2009metacognition}. During metacognitive regulation, an agent engages in continuous self-reflection and introspection, posing questions such as, ``Am I likely to remember this information?'' or ``Will I deploy this module in the next operation?'' and responds accordingly.

Extrapolating metacognitive processes to non-human agents remains controversial. Metacognition has traditionally been viewed as a uniquely human capacity \cite{dunlosky2008metacognition, kornell2009metacognition}, with some scholars arguing that genuine metacognitive ability depends on linguistic structures that enable agents to attribute mental states to themselves \citep{carruthers2008meta}. Accumulating evidence suggests that certain non-human species, such as dolphins, primates, and birds, demonstrate behaviors indicative of meta-level cognitive processing \citep{hampton2009multiple, kornell2007transfer, crystal2009metacognition}. For example, pigeons exhibit selective preferences for tasks requiring distinct working memory demands and engage in information-seeking behavior that mitigates the difficulty of discrimination tasks \citep{castro2013information, iwasaki2018pigeons}. Such evidence may suggest that pigeons monitor their knowledge states and thereby control their environment or adjust their problem-solving strategy. Nonetheless, without self-report instruments for animals, the evidence for animal metacognition remains contingent upon the interpretation of behavioral outcomes.

By analogy, AI agents endowed with metacognitive capabilities can perceive the expansion of their knowledge \citep{souchay2012feeling}, assess confidence levels in their outputs \citep{fleming2014measure}, and adapt their reasoning strategies accordingly \citep{crystal2009metacognition, crystal2011evaluating}. Consider an AI-supported autonomous vehicle: its regulatory subsystem may supervise operational parameters and report errors, yet in the absence of agency or a self-reflective mechanism, such monitoring remains passive and reactive. It lacks the capacity to actively alter primary processes based on internal evaluation. In contrast, truly reflective behavior entails at least the capacity for self-monitoring\textemdash a hallmark of more advanced cognitive agents. Contemporary AI systems increasingly exhibit rudimentary forms of such metacognitive monitoring, including the ability to evaluate and revise their own cognitive operations \citep{johnson2022metacognition, Didolkar2024, walker2025harnessing}.



\paragraph{Self-Awareness}

In terms of behavioral capacity, \textit{Self-awareness} represents the capacity of taking oneself as the object of awareness \citep{morin2011self}, yet it contains a collection of different self-oriented functions: agency, body ownership, self-recognization, interoception (representation of inner bodily state, such as hunger and pain), knowledge boundaries, and autobiographical memory \citep{chapman2020translational, mograbi2024cognitive}. The \emph{self}, as an apparatus that carries an individual's subjective experience, operates with various levels of competence. As early as 1972, \citet{duval1972objective} proposed that self-awareness arises when the agent's attention is directed inward, contrasting with general environmental awareness. Later contributions from social-cognitive psychology frame self-awareness as an information-processing capability linked to self-schema (\ie, a cognitive framework about how individuals perceive, interpret, and behave in various situations) and mechanisms of self-regulation \citep{Morin2006selfawareness, baumeister2010self, carver1981attention}. With the help of neuroimaging techniques, neuropsychology builds up sound self-awareness through lesion studies and cases of deficiency, such as dementia, Alzheimer's disease, and anosognosia\footnote{Meaning the lack of awareness of one’s own illness or deficits (Greek: a-, ``without'', nosos, ``disease'', gnosis, ``knowledge''). Described by Joseph Babinski in 1914, it first characterized stroke patients with left paralysis who did not recognize their hemiplegia \citep{babinski1914contribution}.} \citep{banks2008self, kirsch2021updating, toglia2000understanding}. Based on these definitions, before claiming self-awareness, an individual should at least fuse sensory, proprioceptive, and cognitive data into a coherent agent identity and have access to declarative knowledge about self, stating ``the body, the internal bodily state, the actions, the consequences of those actions, and those past memories belongs to me''. 

Self-awareness is widely regarded as a hallmark of higher-order cognition \citep{baumeister2010self}. By providing the information essential for metacognition, it is foundational for developing self-knowledge, facilitating introspection, enhancing emotional responses, and supporting adaptive self-control \citep{lou2017towards}. Some studies attribute self-awareness under the rubric of metacognition in the context of cognitive psychology \citep{fleming2014measure}, while \citet{Morin2006selfawareness} recognized the differences between meta-self-awareness and perceptual-level self-awareness by extracting the conceptual information about oneself from perceptual information. For example, self-aware agents obtain the intuitive feeling of stomach pain and cramps after long-time starvation; after one's attention shifts to the feeling of hunger, they create a reflexive meta-representational knowledge in their mind. In other words, the phenomenological content of self-awareness remains the discomfort in the stomach, not thoughts about feeling hungry. Neuroimaging reveals their distinctions as well: both are linked to the Default Mode Network (DMN) and its core regions; conscious experiences that are deemed essential for generating self-awareness persistently activate parallel limbic-network areas, specifically the medial prefrontal cortex/anterior cingulate cortex (ACC) and the precuneus/posterior cingulate cortex \citep{lou2017towards}. The neural substrates of metacognition are concentrated within frontal executive-function regions, \eg, the lateral frontopolar cortex (lFPC) and dorsal anterior cingulate cortex (dACC) play critical roles in monitoring decision uncertainty and adjusting strategies, suggesting that metacognition relies upon a distinct prefrontal system \citep{fleming2012neural, qiu2018neural}.

All agents possess knowledge about themselves, but not all form a sufficient, structural knowledge system to support higher cognitive processes. Many animals can respond to inner stimuli or exhibit complex feedback behaviors, yet may lack the capacity to represent themselves as distinct entities or to generate self-referential content \citep{leary2007curse, Morin2006selfawareness}. Mirror self-recognition (MSR) has long been the classic test of self-awareness, and only some primates, elephants, and socially intelligent birds like magpies have been argued to succeed in the test \citep{Gallup1970, plotnik2006self, anderson2015mirror}. Using MSR results as the single criterion is undoubtedly questionable; supportively, mammals and highly intelligent birds exhibit more features in autobiographical memories by matching the new environment with self-referential cues from past experiences \citep{davies2022episodic, martin2013memory, clayton1998episodic}. In the context of artificial intelligence, it may be necessary to undertake a renewed frame of self-awareness, since AI systems display extraordinarily advanced capacities in certain dimensions (\eg, retrieving past environments, no matter in terms of accuracy, reproducibility, or velocity), while the implementation of a primitive sense of body ownership and agency in robots and of how the ontogenetic process shapes robotic self remains ambiguous \citep{hafner2020prerequisites}. Converging perspectives from psychology, neuroscience, and AI characteristics, self-awareness as an advanced cognitive feature may root in self-representation, embodiment, and other physical properties\textemdash not necessarily dependent on so-called ``subjective qualia''\footnote{Philosophical term for the mind-body problem, referring to introspectively accessible phenomenological aspects in some mental states, such as perceptual experiences, bodily sensations, moods, and emotional reactions \citep{Qualiastanford}.} \citep{duval1972objective, carver1981attention, Bongard2006}. %



\begin{figure}[tb]
    \centering
    \begin{subfigure}[t]{0.55\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figs/social-awareness.png}
        \caption{Social Awareness}
        \label{fig:social-awareness}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.35\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figs/situational-awareness.png}
        \caption{Situational Awareness}
        \label{fig:situational-awareness}
    \end{subfigure}
    \caption{Illustration of social awareness and situational awareness as related but distinct components in awareness models}
    \label{fig:last-two}
\end{figure}


\paragraph{Social Awareness}

\textit{Social Awareness} is broadly defined as the cognitive capacity to perceive, interpret, and respond to the social signals, emotions, and perspectives of other agents \citep{lieberman2007social}. This is a multifaceted construct encompassing \emph{theory of mind} (ToM, \ie, the ability to attribute independent mental states such as beliefs, intentions, and knowledge to oneself other agents \citep{Premack1978}), empathy, the understanding of interpersonal relationships, and the knowledge of society: context, cultural, and social norm (see \autoref{fig:social-awareness}). Social awareness forms a foundational basis for self-construction within social contexts \citep{baumeister2010self}. Individuals without neurological deviations gradually acquire the understanding that others possess autonomous beliefs and desires, along with the capacities for perspective-taking and affective empathy \citep{Premack1978,Preston2002,Abbo2024}. By approximately age four, typically developing children succeed in false-belief tasks, evidencing a functioning theory of mind \citep{Wimmer1983}, whereas children with autism spectrum disorder\footnote{A neurodevelopmental disorder characterized by social communication and interaction deficits and repetitive motor behaviors \citep{dsm5}.} frequently struggle with such tasks \citep{BaronCohen1985}. Humans further demonstrate exceptional proficiency in shared intentionality\textemdash the ability to collaboratively comprehend and align with others' goals and perspectives \citep{Tomasello2005}.

Non-human species also exhibit foundational elements of social awareness. Primates \citep{Premack1978} and birds \citep{krupenye2019theory} demonstrate rudimentary theory-of-mind capabilities, the cornerstone for extending emotional and relational knowledge. Animals with social structures and high cognitive functions exhibit pronounced forms of social awareness as well: chimpanzees and other primates can infer the goals and intentions of others and may even engage in deceptive behaviors \citep{kudo2001neocortex}; corvids such as scrub-jays re-hide their food caches when previously observed, indicating awareness of potential pilferers \citep{clayton2007social}; dolphins recognize individual identities and maintain complex, multi-tiered alliances, suggesting an ability to attribute both knowledge and ignorance to conspecifics \citep{connor2007dolphin}.

Early developments in artificial intelligence and robotics sought to model elementary components of social awareness \citep{Rabinowitz2018,cuzzolin2020knowing}. For instance, classical AI agents within multi-agent systems were designed to reason about the beliefs and intentions of other agents (\eg, \citep{muise2022efficient}). Early social robotics integrated rudimentary theory-of-mind modeling and emotion-recognition mechanisms to support basic forms of human-robot interaction \citep{Scassellati2002ToMRobot}. In AI contexts, social awareness entails perceiving and reasoning about the presence, internal states, and potential intentions of other agents (human or artificial). The criteria to identify competencies vary from recognition of social cues to more sophisticated forms of theory-of-mind tasks. For instance, a chatbot that detects user frustration from tone demonstrates external social sensitivity \citep{hu2018touch}, whereas a robot that identifies informational gaps in its human collaborator and proactively offers relevant knowledge exemplifies a more advanced form of interpersonal reasoning \citep{devin2016implemented, iio2020human}.


\paragraph{Situational Awareness} 
\label{subsec:sa}

\textit{Situational awareness} refers to the perception, comprehension, and projection of environmental elements and their future status \citep{munir2022situational, endsley1995toward, flach1995situation, national1998modeling, nofi2000defining}. \citet{endsley1995measurement} formalized SA as “the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in the near future.” This three-level model (\autoref{fig:situational-awareness} provides a thumbnail of its structure) has become the de facto definition of SA across domains: perception defines situations by tagging environmental elements semantically, comprehension integrates information, and projection supports planning and option evaluations \citep{national1998modeling}. Human situational awareness has been extensively studied using both objective and subjective measures in aviation \citep{endsley1995measurement,uhlarik2002review, taylor2017situational}, military \citep{nolan2014framework}, medical care \citep{gaba1995situation, stubbings2012nurses}, and traffic circumstances \citep{gugerty1997situation, ma2005situation}. For objective measures, in simulated aviation battles, \citet{endsley1995measurement} monitored subjects' knowledge about their location, heading direction, altitude, weapon, and information regarding their enemies, utilizing the Situational Awareness Global Assessment Technique (SAGAT) to probe operator knowledge through real-time queries during task interruptions. They integrated subjective self-reported rating scales as well for complementary reflection items. \citet{taylor2017situational} developed a holistic version of the self-report instrument, Situational Awareness Rating Technique (SART), to evaluate perceptions of environmental stability, complexity, variability, etc.

EPfforts to replicate or approximate artificial situational awareness in AI systems involve enabling AI to perceive their environment, contextualize sensory data, and anticipate future events \citep{parasuraman2008situation}. This typically involves integrating multi-sensor data into a coherent, continuously updated workplace \citep{baars2002conscious}. AI-driven frameworks for situational awareness now incorporate semantic knowledge bases and real-time inference engines to track both internal system states and external environmental cues \citep{cornelio2025hierarchical, ruiz2024smart}. For instance, an autonomous vehicle uses situational awareness to monitor nearby vehicles, interpret road conditions, and predict hazards \citep{endsley1995toward, parasuraman2008situation, bavle2023slam}, thereby facilitating adaptive and safe decision-making.

Given the variability of manifestations across psychology, engineering, and cognitive ergonomics \citep{sarter2017situation, nofi2000defining, stanton2010situation}, defining a strict boundary for situational awareness remains challenging yet necessary. By design, AI agents operate within predefined scenarios and possess an embedded awareness of such contexts, which often conflates aspects of self and environmental awareness. Broadly attributing behavioral changes to situational awareness risks circularity in explanation \citep{flach1995situation}. Nevertheless, capabilities such as collision avoidance, dynamic adaptation, and state estimation exemplify environment-focused situational knowledge without implying self-reflective or socially aware capacities. We delineate two concepts by confining situational knowledge to information sources that are not inherently tied to any single agent or social collective. A more cognitively rich example is an AI surveillance system that integrates audio and visual data to infer that a detected noise is caused by wind rather than a human intruder. In some cases, sensorimotor embodiment allows internal metrics, such as CPU load or memory status, to be integrated as part of an agent's situational model. In essence, the defining characteristic of situational awareness constitutes the internal representation of the external world that enables informed decision-making, particularly in complex and dynamic operational contexts.
 
\mytcolorbox{Decomposing awareness into \textit{metacognition, self-, social, and situational} forms provides a tractable framework for evaluating and engineering intelligent systems, \ie, transforming a once vague concept into a practical research agenda.}

\input{Tabs/other_awareness}

\input{Tabs/awareness_of_ai}

\subsection{Theoretical Strengths and Challenges}

The adequacy of this taxonomy allows for explanations of more nuanced forms of awareness through combinations of these fundamental categories. \autoref{tab:awareness-mapping} exemplifies that the main components adequately cover several frequently mentioned types of awareness: emotional awareness arises from perceiving one's emotions (self-awareness) and those of others (social awareness); moral or ethical awareness involves evaluating the consequences of actions and making value judgments, thus integrating metacognition and self-awareness \citep{miller2014moral}; context awareness involves recognizing environmental spatial and temporal structures \citep{guesgen2010spatio}. Whether some categories may overlap or not is still under debate. For instance, notwithstanding that we manually segregate ``self-oriented knowledge'' and ``knowledge of knowing'', the intersectionality of metacognition and self-awareness depends on the rubric and paradigm of research \citep{chapman2020translational}. Meanwhile, awareness studies encounter the hardship of definition vagueness, lack of unified objective indicators for evaluation, challenges posed by inconsistent interdisciplinary frameworks and objectives, and ethical concerns\textemdash we will elaborate in the following sections.

Despite being controversial, LLM dialogue systems are demonstrating a more complete awareness structure. As shown in \autoref{tab:awareness-comparison}, they exhibit a broader spectrum of cognitive capacities than robots designed for specific functions and even surpass those of some animals. They demonstrate robust mental-state reasoning in text, perform significantly better on general abilities than animals, and even exhibit advanced cognitive capacities that require profound understanding of the knowledge in their awareness pool, such as deception \citep{hagendorff2024deception, hagendorff2024we, strachan2024testing}. By properly regulating its strengths and weaknesses, they may have the potential to explore comprehensive awareness. In the following sections, we will explore how researchers have constructed criteria and evaluation methods to measure LLM's capacity in ``being aware of everything''. 





\mytcolorbox{A principled taxonomy of awareness, spanning metacognition, self-awareness, social awareness, and situational awareness, provides \emph{not only} a foundation for empirical research, \emph{but also} a roadmap for building more general, adaptable, and transparent AI systems. Understanding the interplay and boundaries among these dimensions is crucial both for scientific advancement and the responsible development of AI.}
